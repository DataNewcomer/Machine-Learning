{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ENSEMBLE METHOD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.051</td>\n",
       "      <td>28.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.055</td>\n",
       "      <td>47.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>49.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.048</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              7.0              0.27         0.36            20.7      0.045   \n",
       "1              6.3              0.30         0.34             1.6      0.049   \n",
       "2              8.1              0.28         0.40             6.9      0.050   \n",
       "3              7.2              0.23         0.32             8.5      0.058   \n",
       "4              7.2              0.23         0.32             8.5      0.058   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "515            6.1              0.31         0.26             2.2      0.051   \n",
       "516            6.8              0.18         0.37             1.6      0.055   \n",
       "517            7.4              0.15         0.42             1.7      0.045   \n",
       "518            5.9              0.13         0.28             1.9      0.050   \n",
       "519            7.2              0.34         0.34            12.6      0.048   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                   14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                   30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                   47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                   47.0                 186.0   0.9956  3.19       0.40   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "515                 28.0                 167.0   0.9926  3.37       0.47   \n",
       "516                 47.0                 154.0   0.9934  3.08       0.45   \n",
       "517                 49.0                 154.0   0.9920  3.00       0.60   \n",
       "518                 20.0                  78.0   0.9918  3.43       0.64   \n",
       "519                  7.0                  41.0   0.9940   NaN        NaN   \n",
       "\n",
       "     alcohol  quality  \n",
       "0        8.8      6.0  \n",
       "1        9.5      6.0  \n",
       "2       10.1      6.0  \n",
       "3        9.9      6.0  \n",
       "4        9.9      6.0  \n",
       "..       ...      ...  \n",
       "515     10.4      6.0  \n",
       "516      9.1      5.0  \n",
       "517     10.4      6.0  \n",
       "518     10.8      6.0  \n",
       "519      NaN      NaN  \n",
       "\n",
       "[520 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('white_wine.csv')\n",
    "df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing value\n",
    "df_wine['alcohol'].fillna(df_wine['alcohol'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename target\n",
    "df_wine['label'] = np.where(df_wine['quality']>6, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x y\n",
    "X = df_wine[['alcohol','density']]\n",
    "y = df_wine['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y, random_state=10, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (Base Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base learner\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=0)\n",
      "0.45161290322580644\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "0.6111111111111112\n",
      "DecisionTreeClassifier(max_depth=5, random_state=0)\n",
      "0.8648648648648648\n"
     ]
    }
   ],
   "source": [
    "list_model = [logreg, knn, tree]\n",
    "\n",
    "for i in list_model:\n",
    "\n",
    "    # fitting\n",
    "    model = i\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base learner\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier([\n",
    "    ('clf1', logreg),\n",
    "    ('clf2', knn),\n",
    "    ('clf3', tree)\n",
    "])\n",
    "\n",
    "# fitting\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        84\n",
      "           1       0.71      0.50      0.59        20\n",
      "\n",
      "    accuracy                           0.87       104\n",
      "   macro avg       0.80      0.73      0.75       104\n",
      "weighted avg       0.86      0.87      0.86       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "logreg_pipe = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('model', logreg)\n",
    "])\n",
    "\n",
    "# knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "scaler = StandardScaler()\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('model', knn)\n",
    "])\n",
    "\n",
    "# dec tree\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('poly', PolynomialFeatures(degree=3)),\n",
      "                ('model', LogisticRegression(random_state=0))])\n",
      "0.8571428571428571\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model', KNeighborsClassifier(n_neighbors=3))])\n",
      "0.9268292682926829\n",
      "DecisionTreeClassifier(max_depth=5, random_state=0)\n",
      "0.8648648648648648\n"
     ]
    }
   ],
   "source": [
    "list_model = [logreg_pipe, knn_pipe, tree]\n",
    "\n",
    "for i in list_model:\n",
    "\n",
    "    # fitting\n",
    "    model = i\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier([\n",
    "    ('clf1', logreg_pipe),\n",
    "    ('clf2', knn_pipe),\n",
    "    ('clf3', tree)\n",
    "])\n",
    "\n",
    "# fitting\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        84\n",
      "           1       0.94      0.80      0.86        20\n",
      "\n",
      "    accuracy                           0.95       104\n",
      "   macro avg       0.95      0.89      0.92       104\n",
      "weighted avg       0.95      0.95      0.95       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base learner\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('poly', PolynomialFeatures(degree=3)),\n",
      "                ('model', LogisticRegression(random_state=0))])\n",
      "0.8571428571428571\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model', KNeighborsClassifier(n_neighbors=3))])\n",
      "0.9268292682926829\n",
      "DecisionTreeClassifier(max_depth=5, random_state=0)\n",
      "0.8648648648648648\n",
      "RandomForestClassifier(random_state=0)\n",
      "0.9268292682926829\n"
     ]
    }
   ],
   "source": [
    "list_model = [logreg_pipe, knn_pipe, tree, rf]\n",
    "\n",
    "for i in list_model:\n",
    "\n",
    "    # fitting\n",
    "    model = i\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari 4 kandidat model, RandomForest adalah model terbaik saat diprediksi ke Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation (mencari model terbaik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81481481 0.58333333 0.66666667 0.78571429 0.76923077] Pipeline(steps=[('poly', PolynomialFeatures(degree=3)),\n",
      "                ('model', LogisticRegression(random_state=0))])\n",
      "[0.90322581 0.93333333 0.90322581 0.96969697 0.90322581] Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model', KNeighborsClassifier(n_neighbors=3))])\n",
      "[0.86666667 0.88888889 0.86666667 0.9375     0.81481481] DecisionTreeClassifier(max_depth=5, random_state=0)\n",
      "[0.90322581 0.93333333 0.90322581 0.9375     0.96774194] RandomForestClassifier(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "list_model = [logreg_pipe, knn_pipe, tree, rf]\n",
    "\n",
    "f1_mean = []\n",
    "f1_std = []\n",
    "\n",
    "for i in list_model:\n",
    "\n",
    "    model_cv = cross_val_score(\n",
    "        estimator=i,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        scoring='f1',\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    print(model_cv, i)\n",
    "\n",
    "    f1_mean.append(model_cv.mean())\n",
    "    f1_std.append(model_cv.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PolynomialFeatures(degree=3), LogisticRegress...</td>\n",
       "      <td>0.723952</td>\n",
       "      <td>0.086228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(StandardScaler(), KNeighborsClassifier(n_neig...</td>\n",
       "      <td>0.922542</td>\n",
       "      <td>0.026304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=5, random_sta...</td>\n",
       "      <td>0.874907</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.929005</td>\n",
       "      <td>0.024169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model   f1_mean    f1_std\n",
       "0  (PolynomialFeatures(degree=3), LogisticRegress...  0.723952  0.086228\n",
       "1  (StandardScaler(), KNeighborsClassifier(n_neig...  0.922542  0.026304\n",
       "2  DecisionTreeClassifier(max_depth=5, random_sta...  0.874907  0.039649\n",
       "3  (DecisionTreeClassifier(max_features='auto', r...  0.929005  0.024169"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'model': list_model,\n",
    "    'f1_mean': f1_mean,\n",
    "    'f1_std': f1_std,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari 4 kandidat model, RandomForest adalah model terbaik berdasarkan cross validation pada training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(range(100, 1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam space \n",
    "\n",
    "hyperparam_space = {\n",
    "    'n_estimators': list(range(100, 1000, 1)),       # jumlah pohon\n",
    "    'max_depth':  list(range(1, 100, 1)),                                 # kedalaman pohon\n",
    "    'max_features': list(range(1, 2, 1)),                               # jumlah feature untuk tiap splitting\n",
    "    'min_samples_split': list(range(2, 100, 1)),                         # jumlah sample sebelum splitting\n",
    "    'min_samples_leaf': list(range(1, 100, 1))                         # jumlah sample sesudah splitting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        'max_features': [1],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...],\n",
       "                                        'n_estimators': [100, 101, 102, 103,\n",
       "                                                         104, 105, 106, 107,\n",
       "                                                         108, 109, 110, 111,\n",
       "                                                         112, 113, 114, 115,\n",
       "                                                         116, 117, 118, 119,\n",
       "                                                         120, 121, 122, 123,\n",
       "                                                         124, 125, 126, 127,\n",
       "                                                         128, 129, ...]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomized search\n",
    "radom_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=hyperparam_space,\n",
    "    n_iter=20,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "radom_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score 0.8274586333207022\n",
      "Best param {'n_estimators': 111, 'min_samples_split': 62, 'min_samples_leaf': 10, 'max_features': 1, 'max_depth': 90}\n"
     ]
    }
   ],
   "source": [
    "print('Best f1 score', radom_search.best_score_)\n",
    "print('Best param', radom_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.520479</td>\n",
       "      <td>0.126175</td>\n",
       "      <td>0.166460</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>111</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_estimators': 111, 'min_samples_split': 62,...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.827459</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.793410</td>\n",
       "      <td>0.204924</td>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>265</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_estimators': 265, 'min_samples_split': 61,...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.061835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.006546</td>\n",
       "      <td>0.282866</td>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.078981</td>\n",
       "      <td>664</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>{'n_estimators': 664, 'min_samples_split': 45,...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.771880</td>\n",
       "      <td>0.083016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.053441</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.533851</td>\n",
       "      <td>0.089037</td>\n",
       "      <td>333</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>{'n_estimators': 333, 'min_samples_split': 78,...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.766199</td>\n",
       "      <td>0.049435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.066214</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.295393</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>255</td>\n",
       "      <td>82</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 255, 'min_samples_split': 82,...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.745887</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.795086</td>\n",
       "      <td>0.511736</td>\n",
       "      <td>1.295425</td>\n",
       "      <td>0.181602</td>\n",
       "      <td>657</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>{'n_estimators': 657, 'min_samples_split': 60,...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.745887</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.320641</td>\n",
       "      <td>0.217236</td>\n",
       "      <td>1.094186</td>\n",
       "      <td>0.148616</td>\n",
       "      <td>677</td>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>{'n_estimators': 677, 'min_samples_split': 67,...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.728304</td>\n",
       "      <td>0.040914</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.407570</td>\n",
       "      <td>0.143160</td>\n",
       "      <td>0.473554</td>\n",
       "      <td>0.099747</td>\n",
       "      <td>290</td>\n",
       "      <td>90</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>{'n_estimators': 290, 'min_samples_split': 90,...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.686351</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.044366</td>\n",
       "      <td>0.242724</td>\n",
       "      <td>0.695964</td>\n",
       "      <td>0.071888</td>\n",
       "      <td>532</td>\n",
       "      <td>91</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>{'n_estimators': 532, 'min_samples_split': 91,...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.637589</td>\n",
       "      <td>0.091369</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.001050</td>\n",
       "      <td>0.527938</td>\n",
       "      <td>0.916692</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_estimators': 491, 'min_samples_split': 3, ...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.609703</td>\n",
       "      <td>0.123212</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.398279</td>\n",
       "      <td>0.204171</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>439</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>{'n_estimators': 439, 'min_samples_split': 16,...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.609703</td>\n",
       "      <td>0.123212</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.315992</td>\n",
       "      <td>0.148218</td>\n",
       "      <td>0.367569</td>\n",
       "      <td>0.043157</td>\n",
       "      <td>248</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_estimators': 248, 'min_samples_split': 35,...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.705790</td>\n",
       "      <td>0.343217</td>\n",
       "      <td>0.820515</td>\n",
       "      <td>0.219654</td>\n",
       "      <td>609</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>{'n_estimators': 609, 'min_samples_split': 67,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260606</td>\n",
       "      <td>0.319320</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.906278</td>\n",
       "      <td>0.186111</td>\n",
       "      <td>1.298749</td>\n",
       "      <td>0.198089</td>\n",
       "      <td>951</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>{'n_estimators': 951, 'min_samples_split': 15,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.263416</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.694694</td>\n",
       "      <td>0.972801</td>\n",
       "      <td>1.337085</td>\n",
       "      <td>0.244118</td>\n",
       "      <td>857</td>\n",
       "      <td>44</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>{'n_estimators': 857, 'min_samples_split': 44,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.846829</td>\n",
       "      <td>0.238375</td>\n",
       "      <td>0.302695</td>\n",
       "      <td>0.083938</td>\n",
       "      <td>147</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 147, 'min_samples_split': 28,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.321311</td>\n",
       "      <td>0.521956</td>\n",
       "      <td>0.666386</td>\n",
       "      <td>0.091515</td>\n",
       "      <td>505</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>{'n_estimators': 505, 'min_samples_split': 63,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.671401</td>\n",
       "      <td>0.443351</td>\n",
       "      <td>1.308961</td>\n",
       "      <td>0.102746</td>\n",
       "      <td>789</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 789, 'min_samples_split': 62,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.651298</td>\n",
       "      <td>0.404024</td>\n",
       "      <td>1.158229</td>\n",
       "      <td>0.155286</td>\n",
       "      <td>889</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>{'n_estimators': 889, 'min_samples_split': 54,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.692886</td>\n",
       "      <td>0.399940</td>\n",
       "      <td>0.229829</td>\n",
       "      <td>0.064979</td>\n",
       "      <td>221</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>{'n_estimators': 221, 'min_samples_split': 76,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        1.520479      0.126175         0.166460        0.029561   \n",
       "18       3.793410      0.204924         0.335141        0.015040   \n",
       "8        9.006546      0.282866         0.791511        0.078981   \n",
       "14       5.053441      0.253177         0.533851        0.089037   \n",
       "16       3.066214      0.053691         0.295393        0.025174   \n",
       "2       11.795086      0.511736         1.295425        0.181602   \n",
       "11      12.320641      0.217236         1.094186        0.148616   \n",
       "13       4.407570      0.143160         0.473554        0.099747   \n",
       "5        7.044366      0.242724         0.695964        0.071888   \n",
       "0       10.001050      0.527938         0.916692        0.088600   \n",
       "1        8.398279      0.204171         0.737993        0.129994   \n",
       "15       3.315992      0.148218         0.367569        0.043157   \n",
       "7        8.705790      0.343217         0.820515        0.219654   \n",
       "6       13.906278      0.186111         1.298749        0.198089   \n",
       "10      13.694694      0.972801         1.337085        0.244118   \n",
       "12       2.846829      0.238375         0.302695        0.083938   \n",
       "4        7.321311      0.521956         0.666386        0.091515   \n",
       "3       14.671401      0.443351         1.308961        0.102746   \n",
       "17      12.651298      0.404024         1.158229        0.155286   \n",
       "19       2.692886      0.399940         0.229829        0.064979   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "9                 111                      62                     10   \n",
       "18                265                      61                     17   \n",
       "8                 664                      45                     25   \n",
       "14                333                      78                     14   \n",
       "16                255                      82                     27   \n",
       "2                 657                      60                     27   \n",
       "11                677                      67                     28   \n",
       "13                290                      90                     39   \n",
       "5                 532                      91                     39   \n",
       "0                 491                       3                     42   \n",
       "1                 439                      16                     43   \n",
       "15                248                      35                     46   \n",
       "7                 609                      67                     48   \n",
       "6                 951                      15                     49   \n",
       "10                857                      44                     69   \n",
       "12                147                      28                     53   \n",
       "4                 505                      63                     69   \n",
       "3                 789                      62                     28   \n",
       "17                889                      54                     61   \n",
       "19                221                      76                     62   \n",
       "\n",
       "   param_max_features param_max_depth  \\\n",
       "9                   1              90   \n",
       "18                  1              15   \n",
       "8                   1              77   \n",
       "14                  1              54   \n",
       "16                  1              74   \n",
       "2                   1              62   \n",
       "11                  1              97   \n",
       "13                  1              44   \n",
       "5                   1              45   \n",
       "0                   1               9   \n",
       "1                   1              72   \n",
       "15                  1              17   \n",
       "7                   1              49   \n",
       "6                   1              65   \n",
       "10                  1              69   \n",
       "12                  1              74   \n",
       "4                   1              37   \n",
       "3                   1               1   \n",
       "17                  1              95   \n",
       "19                  1              31   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'n_estimators': 111, 'min_samples_split': 62,...           0.857143   \n",
       "18  {'n_estimators': 265, 'min_samples_split': 61,...           0.857143   \n",
       "8   {'n_estimators': 664, 'min_samples_split': 45,...           0.814815   \n",
       "14  {'n_estimators': 333, 'min_samples_split': 78,...           0.814815   \n",
       "16  {'n_estimators': 255, 'min_samples_split': 82,...           0.769231   \n",
       "2   {'n_estimators': 657, 'min_samples_split': 60,...           0.769231   \n",
       "11  {'n_estimators': 677, 'min_samples_split': 67,...           0.769231   \n",
       "13  {'n_estimators': 290, 'min_samples_split': 90,...           0.608696   \n",
       "5   {'n_estimators': 532, 'min_samples_split': 91,...           0.608696   \n",
       "0   {'n_estimators': 491, 'min_samples_split': 3, ...           0.545455   \n",
       "1   {'n_estimators': 439, 'min_samples_split': 16,...           0.545455   \n",
       "15  {'n_estimators': 248, 'min_samples_split': 35,...           0.545455   \n",
       "7   {'n_estimators': 609, 'min_samples_split': 67,...           0.000000   \n",
       "6   {'n_estimators': 951, 'min_samples_split': 15,...           0.000000   \n",
       "10  {'n_estimators': 857, 'min_samples_split': 44,...           0.000000   \n",
       "12  {'n_estimators': 147, 'min_samples_split': 28,...           0.000000   \n",
       "4   {'n_estimators': 505, 'min_samples_split': 63,...           0.000000   \n",
       "3   {'n_estimators': 789, 'min_samples_split': 62,...           0.000000   \n",
       "17  {'n_estimators': 889, 'min_samples_split': 54,...           0.000000   \n",
       "19  {'n_estimators': 221, 'min_samples_split': 76,...           0.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9            0.750000           0.769231           0.827586   \n",
       "18           0.695652           0.769231           0.827586   \n",
       "8            0.695652           0.666667           0.785714   \n",
       "14           0.695652           0.720000           0.785714   \n",
       "16           0.695652           0.666667           0.740741   \n",
       "2            0.695652           0.666667           0.740741   \n",
       "11           0.695652           0.666667           0.740741   \n",
       "13           0.695652           0.666667           0.740741   \n",
       "5            0.695652           0.666667           0.740741   \n",
       "0            0.695652           0.666667           0.740741   \n",
       "1            0.695652           0.666667           0.740741   \n",
       "15           0.636364           0.666667           0.454545   \n",
       "7            0.636364           0.666667           0.000000   \n",
       "6            0.500000           0.571429           0.000000   \n",
       "10           0.000000           0.000000           0.000000   \n",
       "12           0.000000           0.000000           0.000000   \n",
       "4            0.000000           0.000000           0.000000   \n",
       "3            0.000000           0.000000           0.000000   \n",
       "17           0.000000           0.000000           0.000000   \n",
       "19           0.000000           0.000000           0.000000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9            0.933333         0.827459        0.065545                1  \n",
       "18           0.857143         0.801351        0.061835                2  \n",
       "8            0.896552         0.771880        0.083016                3  \n",
       "14           0.814815         0.766199        0.049435                4  \n",
       "16           0.857143         0.745887        0.065953                5  \n",
       "2            0.857143         0.745887        0.065953                5  \n",
       "11           0.769231         0.728304        0.040914                7  \n",
       "13           0.720000         0.686351        0.046032                8  \n",
       "5            0.476190         0.637589        0.091369                9  \n",
       "0            0.400000         0.609703        0.123212               10  \n",
       "1            0.400000         0.609703        0.123212               10  \n",
       "15           0.000000         0.460606        0.241969               12  \n",
       "7            0.000000         0.260606        0.319320               13  \n",
       "6            0.000000         0.214286        0.263416               14  \n",
       "10           0.000000         0.000000        0.000000               15  \n",
       "12           0.000000         0.000000        0.000000               15  \n",
       "4            0.000000         0.000000        0.000000               15  \n",
       "3            0.000000         0.000000        0.000000               15  \n",
       "17           0.000000         0.000000        0.000000               15  \n",
       "19           0.000000         0.000000        0.000000               15  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(radom_search.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37eb40c3388cfde35488e2d005b0d69ca91ddeff8a429754d4da636d3f888e5e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
